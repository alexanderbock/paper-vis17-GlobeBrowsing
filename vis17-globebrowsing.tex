\documentclass[journal]{vgtc}                % final (journal style)
%\documentclass[review,journal]{vgtc}         % review (journal style)
%\documentclass[widereview]{vgtc}             % wide-spaced review
%\documentclass[preprint,journal]{vgtc}       % preprint (journal style)

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Please note that the use of figures other than the optional teaser is not permitted on the first page
%% of the journal version.  Figures should begin on the second page and be
%% in CMYK or Grey scale format, otherwise, colour shifting may occur
%% during the printing process.  Papers submitted with figures other than the optional teaser on the
%% first page will be refused. Also, the teaser figure should only have the
%% width of the abstract as the template enforces it.

%% These few lines make a distinction between latex and pdflatex calls and they
%% bring in essential packages for graphics and font handling.
%% Note that due to the \DeclareGraphicsExtensions{} call it is no longer necessary
%% to provide the the path and extension of a graphics file:
%% \includegraphics{diamondrule} is completely sufficient.
%%
\ifpdf%                                % if we use pdflatex
  \pdfoutput=1\relax                   % create PDFs from pdfLaTeX
  \pdfcompresslevel=9                  % PDF Compression
  \pdfoptionpdfminorversion=7          % create PDF 1.7
  \ExecuteOptions{pdftex}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.pdf,.png,.jpg,.jpeg} % for pdflatex we expect .pdf, .png, or .jpg files
\else%                                 % else we use pure latex
  \ExecuteOptions{dvips}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.eps}     % for pure latex we expect eps files
\fi%

%% it is recomended to use ``\autoref{sec:bla}'' instead of ``Fig.~\ref{sec:bla}''
\graphicspath{{figures/}{pictures/}{images/}{./}} % where to search for the images

\usepackage[utf8]{inputenc}
\usepackage{microtype}                 % use micro-typography (slightly more compact, better to read)
\PassOptionsToPackage{warn}{textcomp}  % to address font issues with \textrightarrow
\usepackage{textcomp}                  % use better special symbols
\usepackage{mathptmx}                  % use matching math font
\usepackage{times}                     % we use Times as the main font
\renewcommand*\ttdefault{txtt}         % a nicer typewriter font
\usepackage{cite}                      % needed to automatically sort the references
%\usepackage{color}
\usepackage{xcolor} % Some more colors not defined in "color" package
% \usepackage{tabu}                      % only used for the table example
% \usepackage{booktabs}                  % only used for the table example
\usepackage{todonotes}
\usepackage[draft]{hyperref} % Weeeeird error occurs without this.


\newcommand{\kallecomment}[1]{\textbf{[-Kalle-~}
    \textcolor{orange}{#1}
    \textbf{~]}}

\newcommand{\emilcomment}[1]{\textbf{[-Emil-~}
    \textcolor{red}{#1}
    \textbf{~]}}

\newcommand{\alexcomment}[1]{\textbf{[-Alex-~}
    \textcolor{magenta}{#1}
    \textbf{~]}}

\newcommand{\anderscomment}[1]{\textbf{[-Anders-~}
    \textcolor{cyan}{#1}
    \textbf{~]}}

\newcommand{\etal}{\emph{et~al.}}


%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.

%% In preprint mode you may define your own headline.
%\preprinttext{To appear in IEEE Transactions on Visualization and Computer Graphics.}

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{0}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}
%% please declare the paper type of your paper to help reviewers, only shown in review mode
%% choices:
%% * algorithm/technique
%% * application/design study
%% * evaluation
%% * system
%% * theory/model
\vgtcpapertype{System}

%% Paper title.

\title{Contextualized spatio-temporal planetary surface visualization}

%% This is how authors are specified in the journal style

%% indicate IEEE Member or Student Member in form indicated below
\author{Karl Bladin, Emil Axelsson, Erik Broberg, Carter Emmart, Patric Ljung, \\ Alexander Bock and Anders Ynnerman, \textit{Associate Member, IEEE}}
\authorfooter{
%% insert punctuation at end of each item
\item
 Karl Bladin, Emil Axelsson, Patric Ljung, Anders Ynnerman and Erik Broberg are with Link√∂ping University.
 E-mail: \{ karl.bladin, emil.axelsson, patric.ljung, anders.ynnerman \} @liu.se, erikbr049@student.liu.se
 \item
 Carter Emmart is with American Museum of Natural History. E-mail: carter@amnh.org.
 \item
 Alexander Bock is with New York University. E-mail alexander.bock@nyu.edu
}

%other entries to be set up for journal
\shortauthortitle{Bladin \MakeLowercase{\textit{et al.}}: Contextualized spatio-temporal planetary surface visualization}

%\shortauthortitle{Firstauthor \MakeLowercase{\textit{et al.}}: Paper Title}

%% Abstract section.
\abstract{The mapping of the planets and moons within our solar system is carried out by space organizations such as NASA and ESA.
Image data are collected by instruments on satellites and spacecrafts, and subsequently used in scientific research and mission planning.
While map data from space missions are often shared openly, it can be difficult for non-experts to comprehend the context of the data and understand the acquisition process.

We present an application where scientific mapping data of celestial bodies is contextualized in space and time to enrich the experience in public dissemination as well as to support communication between scientists.
In our system various types of datasets and visualization techniques are combined; 
A chunked level-of-detail approach is used to enable interactive exploration of global maps as well as local high-resolution digital terrain models with textures and height information.
This is particularly interesting for Mars thanks to the extensive amount of map data gathered by the various missions to this planet.
Using time varying data sets, we visualize the dynamics of a celestial body, such as weather conditions on Earth.
Furthermore, we interactively play back in-situ visualizations of the process for data acquisition.

Our work has been implemented in the open source software OpenSpace that enables interactive presentations in immersive environments like dome theaters and virtual reality headsets.

%The mapping of the planets and moons within our solar system is carried out by space organizations such as NASA and ESA.
%Image data are collected by cameras on satellites and spacecrafts, and used in scientific research and in planning of future space missions.
%Despite the fact that NASA shares a lot of its image data openly, it seldom reaches the general public.

%A lot of research has been done in terms of visualizing planetary data using terrain rendering. Current technology relies on techniques such as out-of-core, and dynamic level of detail rendering, multi threaded data acquisition and consideration of precision limitations.

%These systems are often either specialized for researchers where accuracy is the main concern, or for games, where the user experience plays a major role.

%We present an application for visualizing the same data that space scientists analyze in the context of a virtual environment representing the space that we are exploring.
%Given the contextualization that the real space provides, we can model the solar system using positional data for modelling the planets' orbits together with the space probes that explores them.
%In a time varying visualizations we can show the dynamics of a planetary surface as well as the data collection process itself.

%The main focus of this paper is to describe the combination of different datasets gathered for mapping out planets' surface features. 
% particularly Mars due to the extensive amount of map data gathered by the various missions on this planet.

%Our rendering system combines various resolutions of local and global map datasets and presents them together in their real context.
%Using the Geospatial Data Abstraction Library (GDAL), we can preprocess images to match the most common cylindrical projection format used for globe rendering.
%A chunked level of detail approach is used for rendering tiles which are height mapped on the fly.
%This allows for a versatile globe renderer which can easily load new datasets without requiring preprocessing by the rendering software.

%We can use the same data that scientists use in their research for public dissemination and present it, bundled and contextualized, using immersive rendering systems.
%Our software, OpenSpace, is an open source project with the goal of bringing space science to the general public.

%
} % end of abstract

%% Keywords that describe your work. Will show as 'Index Terms' in journal
%% please capitalize first letter and insert punctuation after last keyword
\keywords{Astronomical visualization, globe rendering, public dissemination, science communication, space mission visualization }

%% ACM Computing Classification System (CCS). 
%% See <http://www.acm.org/class/1998/> for details.
%% The ``\CCScat'' command takes four arguments.

\CCScatlist{ % not used in journal version
 \CCScat{K.6.1}{Management of Computing and Information Systems}%
{Project and People Management}{Life Cycle};
 \CCScat{K.7.m}{The Computing Profession}{Miscellaneous}{Ethics}
}

%% Uncomment below to include a teaser figure.
\teaser{
  \centering
  %\includegraphics[width=\linewidth]{CypressView}
  %\caption{In the Clouds: Vancouver from Cypress Mountain. Note that the teaser may not be wider than the abstract block.}
%	\label{fig:teaser}
}

%% Uncomment below to disable the manuscript note
%\renewcommand{\manuscriptnotetxt}{}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

\vgtcinsertpkg

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%% The ``\maketitle'' command must be the first command after the
%% ``\begin{document}'' command. It prepares and prints the title block.

%% the only exception to this rule is the \firstsection command
\firstsection{Introduction} \label{sec:introduction}
\maketitle
\kallecomment{Maybe some more catchy name of the article? "Browsing the Red Planet", "Browsing Mars", "Unveiling Mars"? :P}
\emilcomment{Public dissemination of celestial bodies using spatial-temporal mapping-data ?}
\anderscomment{Spatio-temporal planetary surface data capture, mapping and visualization, 
Immersive visualisation of spatio-temporal planetary surface data capture and mapping ?}


\begin{enumerate}
\item Visualizing space data is important because its expensive

\kallecomment{What is expensive?}

\item There exists a vast amount of data from Mars orbiters

The amount of open data currently available from space missions is extensive.
NASA alone offers more than 100 TB of images from various planetary space missions through the Planetary Data System, which is available as open data \cite{bigdata}.

NASA's Viking program, launched in the year 1975, gathered important information about Mars and its surface features from the two orbiting satellites and the landers put on the surface of the planet.
Today, the most important large scale imaging campaign is carried out by the Mars Reconnaissance Orbiter (MRO).
This satellite carries the MARCI (Mars Color Imager), CTX (Context Camera) and HiRISE (High Resolution Imaging Science Experiment) cameras which are used to image the surface at different resolutions \cite{mromission}.

Our goal is to bring space science to the public as well as providing tools for scientists to talk about space research.
Part of this relies on the ability to visualize planetary science by providing an accurate representation of the globes in our solar system as well as the ability to go there virtually, using the open data available from various space missions.

Raw image data, gathered from space missions, are easily rendered flat on screen. Depending on usage, the images are defined in different projections.
The ground truth is to render images in situ, to recreate the landscapes and build a virtual representation of the actual globes.
It also gives intuitive understanding of how the data is collected by satellites such as the MRO if the images can be rendered in the right context.

Using the tools that scientific data visualization allows, it is possible to get a better understanding of the space missions.
By allowing contol of time flow, showing satellites and space probes in the same context as the planets, and doing this using immersive display systems gives intuitive understanding of the space around us and how scientists gather knowledge about it.

Typical examples of use cases for interactive visualization are large scale dome presentations of real time presentations, virtual reality headsets, and touch tables; where the audience can experience flight through space and time, experiencing our current mapping of the cosmos.

\item Stereoscopic reconstruction from multiple image passes

\kallecomment{Maybe not suitable to put here already?}

\item What datasets are available (Viking, MOLA, CTX, HiRISE) and whats their resolutions

The Mars Global Digital Image Mosaic (MDIM) is a global image dataset with a resolution of 256 pixels/degree \cite{MDIM2.1_web}.
The latest version of this image mosaic, MDIM 2.1 is compiled using a network of images from the Mariner 9 and Viking Orbiters with improved accuracy as a result of constraining control points from the Mars Orbiter Laser Altimeter (MOLA) data \cite{MDIM2.1}.
The dataset is tied to the IAU/IAG 2000 coordinate system which has been adopted by the majority of Mars missions and instrument teams \cite{MDIM2.1}.

The Mars Orbiter Laser Altimeter (MOLA) is an instrument on the Mars Global Surveyor (MGS) spacecraft.
The digital elevation model (DEM) assembled from MOLA data maps each position on the globe with an offset from the Areoid, Mars' reference ellipsoid, to an average horizontal accuracy of ~100 meters \cite{MOLA}. The dataset has a resolution of 463.0836 meters/pixel \cite{MOLA}.

The HiRISE Operations Center provides images from the HiRISE mission. These are grayscale images, infrared, green and blue images mapped to the red green and blue channels, stereo pairs and digital terrain models generated from stereo pairs.

\kallecomment{Other datasets? Does ESA have Mars missions of interest?}

\item How can this be applied to other planets, A system for enabling future research thati s correctly contextualized. What is the science question // What is the point of this

By enabling the ability to read many types of image datasets, with global or local coverage, temporal or static, and doing so dynamically, we can generalize the technique to different globes without having a specific focus group.
We hope that our tools can be useful both for scientists who want to present their work in a contextualized manner and for people who find interest in the subjects we discuss or want to experience the most accurate representation of standing on the surface of Mars using only real data.

\end{enumerate}
Length: About 1 page

\section{Related Work} \label{sec:relatedwork}

Geographical Information Systems (GIS) relies heavily on the ability to gather, transform, and visualize data with geospatial information.
Maps and DEM's are typical examples of such data and research and development of software solutions to handle different parts of GIS, such as rendering, have lead to different applications in space visualization.

\kallecomment{Can Carter write something here? What other relevant softwares, like Google Mars, are in use?}

\subsection{Rendering}

A globe rendering system needs to handle out of core rendering and level of detail management to avoid flooding the data caches and rendering times.

Cozzi and Ring (ref) gives a thorough description of the most common methods used for globe rendering today.
Older level of detail techniques such as Real Time Optimally Adaptive Mesh (ROAM) does not allow full GPU throughput and gives way for techniques such as chunked level of detail and geometry clipmaps.


\subsection{3D Reconstruction From Images}

Adding the third dimension required for terrain rendering is most commonly carried out by rendering DTMs, also known as heigh mapping.
Height map datasets can be generated using measured data from altimeters on the satellites, corrected to match an offset from a reference ellipsoid (ref) in the direction of the geodetic normal for every point on the surface covered by the dataset (ref).
Height maps can also be generated using stereoscopic reconstruction.

\kallecomment{Someone wants to add text about stereo reconstruction here?}

\subsection{Geospatial Data Abstraction}

Geospatial Data Abstraction Library (GDAL) is an open source software package and C++ library enabling re-projection and warping of map datasets and can act as a layer of abstraction between the rendering software and the many different types of map formats and projections.

\begin{enumerate}
\item the book

\kallecomment{3D Engine Design for Virtual Globes?}

\item terrain renderer
\item 3d reconstruction from images (stereoscopic and structure-from-motion)
\item GDAL
\item ``virtual presence'' systems
\item What else?
\end{enumerate}
Length: About 1 page\\
Note:  The page limit was increased to 9+2 pages this year (= 9 pages of manuscript, 2 pages of references). So we should make use of this and cite the hell out of everything that's related

\section{Overview} \label{sec:overview}



\begin{enumerate}
  \item What are the steps to get from a satellite to 3d terrain rendering
\begin{enumerate}
  \item Acquision (MRO information)
  \item Processing (AMES Stereo pipeline, ..., GDAL)
  \item Rendering (Globebrowsing)
\end{enumerate}
  \item short descriptions for each
\end{enumerate}
Length: About 2 pages

\section{Image Acquisition and Processing} \label{sec:imageacquisitionprocessing}
\begin{enumerate}
  \item MRO information, different resolution levels
  \item What are the available data products
  \item Ames stereo pipeline
  \item GDAL preprocessing
  \item WMS

To standardize web requests for map data, the Open GIS Consortium (OGC) specified a web map service interface (ref) and from that, specifications of several other map service interfaces have followed.
The most common standards are Web Map Service (WMS), Tile Map Service (TMS) and Web Map Tile Service (WMTS). Some other, more specific, examples of WMS-like services are WorldWind, VirtualEarth and AGS.
  
\end{enumerate}
Length: About 1-1.5 pages

\section{Rendering System} \label{sec:renderingsystem}


\begin{enumerate}
  \item All the steps to get from GDAL to a rendering on the screen
  
  \kallecomment{Tile pipeline as described in our thesis (but shorter).}
  
  \kallecomment{Abstraction layers.}
  
  \kallecomment{Rendering chunks. Shader implementation on a high level.}
  
  \kallecomment{Atmosphere?!?!!?!}
  
  \item Stereoscopic rendering
  \item Dome rendering
  \item Different resolution levels
  \item Rendering rover locations
\end{enumerate}
Length: About 2-2.5 pages (fill as much as the page limit (9+2) allows)


When the image datasets are in the format required for the renderer, there are several abstraction layers we employ to handle the out of core techniques required for rendering.

Two major concepts used in the rendering system are tiles and chunks. A tile has a texture representing a geodetic area and is uniquely defined by a layer and a tile index.
A layer works much like in image editing softwares and can have different types, analogous to blending options.
Examples are height layers, color layers, grayscale layers or grayscale overlays.
A tile index is defined by a level, x, and y coordinates in the chunk tree structure.

The main globe model consists of a quadtree of chunks.
The chunk renderer has access to a skirted grid (ref) which can be mapped on to a geodetic region and rendered in place using one or several layers.

\subsection{From Dataset to Tile}

Each layer corresponds to its own ``tile provider''.
A tile provider is able to initiate asynchronous calls to a tile data reader which in turn reads the image data from disk or from remote servers.
Once the image data is ready, a tile can be created and pushed in to an in memory LRU cache so that the tile provider can return it upon request.
If the tile is already in the cache, the tile provider simply needs to return it and update the cache upon request.

\kallecomment{Figure}

\subsection{Chunk Rendering}




\section{Conclusion} \label{sec:system}
\begin{enumerate}
  \item Blabla; introduction in reverse
  \item Future work:
  \begin{enumerate}
    \item Focus more on scientific rather than engineering goals
  \end{enumerate}
\end{enumerate}
Length: About 1 page

%% if specified like this the section will be committed in review mode
\acknowledgments{
The authors wish to thank A, B, C. This work was supported in part by
a grant from XYZ.}

%\bibliographystyle{abbrv}
\bibliographystyle{abbrv-doi}
%\bibliographystyle{abbrv-doi-narrow}
%\bibliographystyle{abbrv-doi-hyperref}
%\bibliographystyle{abbrv-doi-hyperref-narrow}

\bibliography{references}

\begin{thebibliography}{99}

\bibitem{bigdata}
\url{https://open.nasa.gov/blog/what-is-nasa-doing-with-big-data-today/}

\bibitem{mromission}
\url{http://pds-imaging.jpl.nasa.gov/portal/mro_mission.html}

\bibitem{MDIM2.1}
\url{https://astrogeology.usgs.gov/search/map/Research/ISPRS/ISPRS04_3006_B_Archinal}

\bibitem{MDIM2.1_web}
\url{https://astrogeology.usgs.gov/search/map/Mars/Viking/MDIM21/Mars_Viking_MDIM21_ClrMosaic_global_232m}

\bibitem{MOLA}
\url{https://astrogeology.usgs.gov/search/map/Mars/GlobalSurveyor/MOLA/Mars_MGS_MOLA_DEM_mosaic_global_463m}

\bibitem{HiRISE_info}
\url{https://astrogeology.usgs.gov/maps/mars-hirise-camera}

\bibitem{HiRISE_data}
\url{http://www.uahirise.org}

\end{thebibliography}

\end{document}

